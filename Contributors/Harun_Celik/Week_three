# Week Two

## Tasks
- [x] Create daily tasks and objectives to be shared with the team.
- [x] Finish DataCamp tutorials around Web data manipulation and API operations in R
- [x] Find and complete tutorials on data handling and pipelining with Tableau 
- [x] Conduct preliminary research on project data/literature review for DHR and AgMRC projects
- [x] Bring in guest speaker to explain operations for ISU's [Mesonet Webpage](https://mesonet.agron.iastate.edu/)



## What I've learned

- **R**
    1. The Farmer's Market project heavily focuses on the extraction of data from different weather organizations as well as datasets for soil data. As an important resource, I continued practicing with APIs and Web scraping by using [Iowa State University's Mesonet](https://mesonet.agron.iastate.edu/). I continued my training in learning the ```rvest``` library.
        <details><summary>Click here for examples of practice codes:</summary>
            Packages

            ```{R }
            library(dplyr)
            library(ggplot2)
            library(rvest)
            library(xml2)
            library(readr)
            library(tidyr)
            ```

            ```{r Loading a webpage through read_html}
            # Reading the URL to import the table
            mesonet_web <- read_html("https://mesonet.agron.iastate.edu/rainfall/bypoint.phtml?syear=2022&eyear=2022&view=online&method=geocode&lat=&street=640+Lincoln+Way&nwsli=&lon=&city=Ames")

            # This code shows the xml structure of the web page
            xml_structure(mesonet_web)
            ```

            ```{r Using xml_find_all to find a node}
            #this code is to find the proper node where information is contained
            meso_rev_nodes <- xml_find_all(mesonet_web, "//pre")

            #convert the xml into a text file
            meso_pre <- xml_text(meso_rev_nodes)
            ```

            ```{r Using xml_attrs and xml_attr to find attributes}
            # This code doesn't actually output any attributes so the container could be containing text instead.
            xml_attrs(meso_rev_nodes)

            #This code proves that inside the node '/pre' is actually just a text file
            xml_structure(meso_rev_nodes)
            ```

            ```{r Using read_lines to read scraped txt file}
            #This code reads the text file from the extracted xml
            meso_text <- read_lines(meso_pre, skip = 5)
            ```

            ```{r Trying to create a data frame from extracted text}
            meso_df_csv <- data.frame(meso_text)
            ```

            ```{r Cleaning data so values are in two different rows}
            # This cleans the data from NA values as well as rows which don't contain the necessary data
            cleaned <- meso_df_csv %>%
            separate(meso_text, into = c("Date", "Inches_Rain"), sep = ", ", convert = TRUE) %>%
            filter(!is.na(Inches_Rain))
            ```
        </details>


